{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\pooria\\anaconda3\\envs\\myonlyenv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contexual_bandit():\n",
    "    def __init__(self):\n",
    "        self.state = 0\n",
    "        self.bandits = np.array([[0.2,0,-0.0,-5],[0.1,-5,1,0.25],[-5,5,5,5]])\n",
    "        \n",
    "        self.num_bandits = self.bandits.shape[0]\n",
    "        self.num_actions = self.bandits.shape[1]\n",
    "        \n",
    "    def getBandit(self):\n",
    "        self.state = np.random.randint(0,len(self.bandits))\n",
    "        \n",
    "        return self.state\n",
    "    def pullArm(self,action):\n",
    "        bandit = self.bandits[self.state,action]\n",
    "        res = np.random.randn(1)\n",
    "        \n",
    "        if(res > bandit):\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, lr, s_size, a_size):\n",
    "        self.state_in = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "        state_in_OH = slim.one_hot_encoding(self.state_in,s_size)\n",
    "        output = slim.fully_connected(state_in_OH,a_size,biases_initializer=None,activation_fn=tf.nn.sigmoid,weights_initializer=tf.ones_initializer())\n",
    "        \n",
    "        self.output = tf.reshape(output,[-1])\n",
    "        self.chosen_action = tf.arg_max(self.output,0)\n",
    "        \n",
    "        self.reward_holder = tf.placeholder(shape=[1],dtype=tf.float32)\n",
    "        self.action_holder = tf.placeholder(shape=[1],dtype=tf.int32)\n",
    "        \n",
    "        self.responsible_weight = tf.slice(self.output,self.action_holder,[1])\n",
    "        self.loss = -(tf.log(self.responsible_weight)*self.reward_holder)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "        self.update = self.optimizer.minimize(self.loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "cBandit = contexual_bandit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "myAgent = Agent(lr=0.001, s_size=cBandit.num_bandits, a_size=cBandit.num_actions)\n",
    "trainables = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = trainables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 10000\n",
    "total_reward = np.zeros(shape=[cBandit.num_bandits,cBandit.num_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of every one of the actions :[ 0.   -0.25  0.  ]\n",
      "mean of every one of the actions :[34.75 37.5  36.5 ]\n",
      "mean of every one of the actions :[68.75 75.25 72.75]\n",
      "mean of every one of the actions :[107.25 112.25 106.75]\n",
      "mean of every one of the actions :[145.5  146.   145.75]\n",
      "mean of every one of the actions :[181.5  182.5  183.25]\n",
      "mean of every one of the actions :[218.25 223.   216.5 ]\n",
      "mean of every one of the actions :[257.   259.75 253.  ]\n",
      "mean of every one of the actions :[296.75 297.25 288.25]\n",
      "mean of every one of the actions :[335.   335.25 322.  ]\n",
      "mean of every one of the actions :[376.   374.75 356.5 ]\n",
      "mean of every one of the actions :[415.75 416.   388.  ]\n",
      "mean of every one of the actions :[456.25 457.5  417.5 ]\n",
      "mean of every one of the actions :[496.25 491.5  453.  ]\n",
      "mean of every one of the actions :[537.   528.   482.75]\n",
      "mean of every one of the actions :[575.   563.   516.75]\n",
      "mean of every one of the actions :[613.5  603.25 555.5 ]\n",
      "mean of every one of the actions :[652.25 634.25 598.25]\n",
      "mean of every one of the actions :[690.5  674.25 632.  ]\n",
      "mean of every one of the actions :[727.25 712.   670.  ]\n",
      "the agent thinks the suitable action for this bandit is : 3\n",
      "and it was right ...\n",
      "the agent thinks the suitable action for this bandit is : 1\n",
      "and it was right ...\n",
      "the agent thinks the suitable action for this bandit is : 0\n",
      "and it was right ...\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess :\n",
    "    sess.run(init)\n",
    "    i=0\n",
    "    while i < total_episodes:\n",
    "        s = cBandit.getBandit()\n",
    "        \n",
    "        if np.random.rand(1) < e :\n",
    "            action = np.random.randint(cBandit.num_actions)\n",
    "        else:\n",
    "            action = sess.run(myAgent.chosen_action,feed_dict={myAgent.state_in:[s]})\n",
    "        \n",
    "        reward = cBandit.pullArm(action)\n",
    "        \n",
    "        feed_dict={myAgent.state_in:[s],myAgent.action_holder:[action],myAgent.reward_holder:[reward]}\n",
    "        \n",
    "        _,ww = sess.run([myAgent.update,weights],feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        total_reward[s,action] += reward\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print('mean of every one of the actions :'+str(np.mean(total_reward,axis=1)))\n",
    "        i+=1\n",
    "for a in range(cBandit.num_bandits):\n",
    "    print('the agent thinks the suitable action for this bandit is : '+str(np.argmax(ww[a])))\n",
    "    if np.argmax(ww[a]) == np.argmin(cBandit.bandits[a]):\n",
    "        print('and it was right ...')\n",
    "    else:\n",
    "        print('and it was wrong ...')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
